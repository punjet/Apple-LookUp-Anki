{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ðŸ·ï¸ **Credits & License**\n",
        "\n",
        "* ðŸ”— [Qwen3-TTS GitHub Repository](https://github.com/QwenLM/Qwen3-TTS)\n",
        "* ðŸ¤— [Qwen3-TTS on Hugging Face](https://huggingface.co/collections/Qwen/qwen3-tts)\n",
        "* ðŸ“„ **License**: Provided under the [Apache License 2.0](https://github.com/QwenLM/Qwen3-TTS?tab=Apache-2.0-1-ov-file)\n",
        "* ðŸ¤— [Try Qwen3-TTS on HuggingFace Space](https://huggingface.co/spaces/Qwen/Qwen3-TTS)\n",
        "\n",
        "\n",
        "\n",
        "### âš ï¸ **Usage Disclaimer**\n",
        "\n",
        "Use of this voice cloning model is subject to strict ethical and legal standards. By using this tool, you agree **not to** engage in any of the following prohibited activities:\n",
        "\n",
        "* **Fraud or Deception**: Using cloned voices to create misleading or fraudulent content.\n",
        "* **Impersonation**: Replicating someoneâ€™s voice without their explicit permission, especially for malicious, harmful, or deceptive purposes.\n",
        "* **Illegal Activities**: Employing the model in any manner that violates local, national, or international laws and regulations.\n",
        "* **Harmful Content Generation**: Creating offensive, defamatory, or unethical material, including content that spreads misinformation or causes harm.\n",
        "\n",
        "> âš–ï¸ **Legal Responsibility**\n",
        "> The developers of this tool disclaim all liability for misuse. **Users bear full responsibility** for ensuring that their usage complies with all applicable laws, regulations, and ethical guidelines.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O5hhJS2moOhU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "57sW-0cHjthT"
      },
      "outputs": [],
      "source": [
        "#@title Install Qwen3-TTS\n",
        "%cd /content/\n",
        "# !rm -rf /content/Qwen3-TTS-Colab\n",
        "!git clone https://github.com/NeuralFalconYT/Qwen3-TTS-Colab.git\n",
        "!git clone https://github.com/QwenLM/Qwen3-TTS.git\n",
        "%cd Qwen3-TTS\n",
        "!pip install -e .\n",
        "!pip install faster-whisper==1.1.1\n",
        "!pip install ctranslate2==4.5.0\n",
        "!pip install pysrt\n",
        "!pip install sentencex\n",
        "from IPython.display import Audio,display\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "clear_output()\n",
        "\n",
        "display(Audio(\"https://raw.githubusercontent.com/NeuralFalconYT/Useful-Function/refs/heads/main/audio/warning.mp3\", autoplay=True))\n",
        "time.sleep(6)\n",
        "clear_output()\n",
        "# time.sleep(5)\n",
        "# import os\n",
        "# os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Qwen3-TTS-Colab\n",
        "!python app.py --share --debug"
      ],
      "metadata": {
        "id": "v7Y8L5EDpYNU",
        "outputId": "a8d6dfd1-d806-47b9-d4b4-ac1bc063b908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Qwen3-TTS-Colab\n",
            "2026-02-24 21:13:29.955773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771967609.975963    1079 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771967609.982721    1079 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771967609.999872    1079 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771967609.999895    1079 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771967609.999899    1079 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771967609.999902    1079 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-24 21:13:30.004304: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "********\n",
            "Warning: flash-attn is not installed. Will only run the manual PyTorch version. Please install flash-attn for faster inference.\n",
            "********\n",
            " \n",
            "/bin/sh: 1: sox: not found\n",
            "WARNING:sox:SoX could not be found!\n",
            "\n",
            "    If you do not have SoX, proceed here:\n",
            "     - - - http://sox.sourceforge.net/ - - -\n",
            "\n",
            "    If you do (or think that you should) have SoX, double-check your\n",
            "    path variables.\n",
            "    \n",
            "/content/Qwen3-TTS-Colab/app.py:354: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=theme, css=css, title=\"Qwen3-TTS Demo\") as demo:\n",
            "/content/Qwen3-TTS-Colab/app.py:354: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=theme, css=css, title=\"Qwen3-TTS Demo\") as demo:\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://6634464bba4710ad67.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Starting transcription for: /tmp/gradio/55491b8b1e3831ca75d4dd3d968aa0ece24cf81b27943b7082a310a85f9d3c99/samplegoblinforai1.png.wav\n",
            "preprocessor_config.json: 100% 340/340 [00:00<00:00, 2.96MB/s]\n",
            "tokenizer.json: 0.00B [00:00, ?B/s]\n",
            "config.json: 2.26kB [00:00, 4.63MB/s]\n",
            "\n",
            "tokenizer.json: 2.71MB [00:00, 119MB/s]\n",
            "vocabulary.json: 1.07MB [00:00, 67.7MB/s]\n",
            "model.bin: 100% 1.62G/1.62G [00:13<00:00, 119MB/s]\n",
            "Starting transcription for: /tmp/gradio/55491b8b1e3831ca75d4dd3d968aa0ece24cf81b27943b7082a310a85f9d3c99/samplegoblinforai1.png.wav\n",
            "Fetching 13 files:   0% 0/13 [00:00<?, ?it/s]\n",
            ".gitattributes: 1.52kB [00:00, 986kB/s]\n",
            "\n",
            "config.json: 2.34kB [00:00, 5.85MB/s]\n",
            "\n",
            "preprocessor_config.json: 100% 127/127 [00:00<00:00, 1.30MB/s]\n",
            "Fetching 13 files:   8% 1/13 [00:00<00:01,  6.97it/s]\n",
            "README.md: 0.00B [00:00, ?B/s]\u001b[A\n",
            "\n",
            "generation_config.json: 100% 245/245 [00:00<00:00, 1.92MB/s]\n",
            "\n",
            "\n",
            "README.md: 57.8kB [00:00, 9.47MB/s]\n",
            "\n",
            "config.json: 4.49kB [00:00, 6.71MB/s]\n",
            "merges.txt: 1.67MB [00:00, 74.9MB/s]\n",
            "\n",
            "model.safetensors:   0% 0.00/3.86G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "configuration.json: 100% 76.0/76.0 [00:00<00:00, 841kB/s]\n",
            "\n",
            "\n",
            "tokenizer_config.json: 7.34kB [00:00, 51.4MB/s]\n",
            "\n",
            "\n",
            "preprocessor_config.json: 100% 234/234 [00:00<00:00, 2.21MB/s]\n",
            "\n",
            "\n",
            "vocab.json: 2.78MB [00:00, 102MB/s]\n",
            "\n",
            "\n",
            "speech_tokenizer/model.safetensors:   0% 0.00/682M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:   1% 7.34M/682M [00:00<00:33, 19.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:   5% 32.9M/682M [00:00<00:08, 75.1MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:   0% 808k/3.86G [00:00<58:09, 1.11MB/s]\u001b[A\n",
            "model.safetensors:   0% 2.24M/3.86G [00:00<23:03, 2.79MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:   7% 45.3M/682M [00:01<00:23, 27.3MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:   2% 69.3M/3.86G [00:07<06:40, 9.47MB/s]\u001b[A\n",
            "model.safetensors:   4% 136M/3.86G [00:07<02:48, 22.1MB/s] \u001b[A\n",
            "model.safetensors:   5% 203M/3.86G [00:07<01:33, 39.3MB/s]\u001b[A\n",
            "model.safetensors:   7% 270M/3.86G [00:08<00:58, 61.6MB/s]\u001b[A\n",
            "model.safetensors:   9% 338M/3.86G [00:08<00:44, 79.4MB/s]\u001b[A\n",
            "model.safetensors:  11% 407M/3.86G [00:08<00:32, 106MB/s] \u001b[A\n",
            "model.safetensors:  12% 474M/3.86G [00:08<00:23, 142MB/s]\u001b[A\n",
            "model.safetensors:  14% 541M/3.86G [00:08<00:18, 183MB/s]\u001b[A\n",
            "model.safetensors:  16% 608M/3.86G [00:09<00:16, 201MB/s]\u001b[A\n",
            "model.safetensors:  17% 675M/3.86G [00:09<00:15, 204MB/s]\u001b[A\n",
            "model.safetensors:  19% 742M/3.86G [00:09<00:13, 230MB/s]\u001b[A\n",
            "model.safetensors:  21% 809M/3.86G [00:10<00:12, 235MB/s]\u001b[A\n",
            "model.safetensors:  23% 876M/3.86G [00:12<00:37, 80.2MB/s]\u001b[A\n",
            "model.safetensors:  24% 943M/3.86G [00:12<00:27, 105MB/s] \u001b[A\n",
            "model.safetensors:  26% 1.01G/3.86G [00:12<00:21, 135MB/s]\u001b[A\n",
            "model.safetensors:  28% 1.08G/3.86G [00:12<00:17, 155MB/s]\u001b[A\n",
            "model.safetensors:  30% 1.14G/3.86G [00:12<00:13, 199MB/s]\u001b[A\n",
            "model.safetensors:  31% 1.21G/3.86G [00:13<00:14, 179MB/s]\u001b[A\n",
            "model.safetensors:  33% 1.28G/3.86G [00:13<00:12, 214MB/s]\u001b[A\n",
            "model.safetensors:  35% 1.35G/3.86G [00:13<00:10, 241MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  16% 112M/682M [00:13<01:23, 6.85MB/s] \u001b[A\u001b[A\n",
            "model.safetensors:  37% 1.41G/3.86G [00:14<00:13, 183MB/s]\u001b[A\n",
            "model.safetensors:  38% 1.48G/3.86G [00:14<00:11, 211MB/s]\u001b[A\n",
            "model.safetensors:  40% 1.55G/3.86G [00:14<00:10, 223MB/s]\u001b[A\n",
            "model.safetensors:  42% 1.61G/3.86G [00:15<00:09, 234MB/s]\u001b[A\n",
            "model.safetensors:  44% 1.68G/3.86G [00:15<00:09, 240MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  26% 179M/682M [00:15<00:41, 12.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  36% 246M/682M [00:15<00:21, 20.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  51% 347M/682M [00:18<00:12, 26.7MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  45% 1.75G/3.86G [00:18<00:34, 61.0MB/s]\u001b[A\n",
            "model.safetensors:  47% 1.82G/3.86G [00:18<00:25, 81.2MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  61% 414M/682M [00:24<00:14, 18.4MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  49% 1.88G/3.86G [00:24<01:09, 28.3MB/s]\u001b[A\n",
            "model.safetensors:  51% 1.95G/3.86G [00:24<00:48, 39.0MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  71% 481M/682M [00:30<00:13, 15.2MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  52% 2.02G/3.86G [00:30<01:21, 22.5MB/s]\u001b[A\n",
            "model.safetensors:  54% 2.08G/3.86G [00:30<00:56, 31.2MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  80% 548M/682M [00:34<00:08, 15.5MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  56% 2.15G/3.86G [00:34<01:09, 24.7MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  90% 615M/682M [00:35<00:03, 20.4MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  57% 2.22G/3.86G [00:35<00:55, 29.7MB/s]\u001b[A\n",
            "model.safetensors:  59% 2.28G/3.86G [00:40<01:11, 22.1MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors: 100% 682M/682M [00:40<00:00, 16.8MB/s]\n",
            "\n",
            "model.safetensors:  60% 2.32G/3.86G [00:41<00:59, 26.0MB/s]\u001b[A\n",
            "model.safetensors:  62% 2.39G/3.86G [00:42<00:48, 30.1MB/s]\u001b[A\n",
            "model.safetensors:  64% 2.45G/3.86G [00:43<00:34, 40.6MB/s]\u001b[A\n",
            "model.safetensors:  65% 2.52G/3.86G [00:46<00:46, 28.5MB/s]\u001b[A\n",
            "model.safetensors:  69% 2.65G/3.86G [00:47<00:24, 49.8MB/s]\u001b[A\n",
            "model.safetensors:  70% 2.72G/3.86G [00:47<00:18, 60.2MB/s]\u001b[A\n",
            "model.safetensors:  72% 2.79G/3.86G [00:53<00:35, 30.2MB/s]\u001b[A\n",
            "model.safetensors:  74% 2.85G/3.86G [00:53<00:24, 40.9MB/s]\u001b[A\n",
            "model.safetensors:  76% 2.92G/3.86G [00:53<00:17, 53.7MB/s]\u001b[A\n",
            "model.safetensors:  77% 2.99G/3.86G [00:53<00:12, 69.8MB/s]\u001b[A\n",
            "model.safetensors:  79% 3.05G/3.86G [00:53<00:09, 87.8MB/s]\u001b[A\n",
            "model.safetensors:  81% 3.12G/3.86G [00:59<00:23, 32.0MB/s]\u001b[A\n",
            "model.safetensors:  83% 3.19G/3.86G [00:59<00:15, 44.0MB/s]\u001b[A\n",
            "model.safetensors:  84% 3.25G/3.86G [00:59<00:11, 54.4MB/s]\u001b[A\n",
            "model.safetensors:  86% 3.32G/3.86G [01:00<00:07, 71.3MB/s]\u001b[A\n",
            "model.safetensors:  88% 3.39G/3.86G [01:05<00:15, 30.4MB/s]\u001b[A\n",
            "model.safetensors:  91% 3.52G/3.86G [01:05<00:06, 51.6MB/s]\u001b[A\n",
            "model.safetensors:  93% 3.59G/3.86G [01:09<00:07, 35.8MB/s]\u001b[A\n",
            "model.safetensors:  95% 3.66G/3.86G [01:09<00:04, 47.5MB/s]\u001b[A\n",
            "model.safetensors:  97% 3.72G/3.86G [01:09<00:02, 60.7MB/s]\u001b[A\n",
            "model.safetensors: 100% 3.86G/3.86G [01:13<00:00, 52.4MB/s]\n",
            "Fetching 13 files: 100% 13/13 [01:13<00:00,  5.68s/it]\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Stitching 1 audio files...\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n"
          ]
        }
      ]
    }
  ]
}